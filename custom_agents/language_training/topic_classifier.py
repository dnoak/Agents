import asyncio
import json
import os
from typing import Any, Literal, Optional
from pydantic import BaseModel, Field
from models.agent import Classifier, Processor, Replicator, Tool
from src.message import Message, Messages
from src.agent import Agent
from src.llm import LLM, LlmApi
from src.instructions import LlmInstructions
import logging
import numpy as np
from rich import print

logging.getLogger("LiteLLM").setLevel(logging.CRITICAL)

class TopicClassifierLLMOutput(Replicator):
    response_analysis: list[str] = Field(
        description='A detailed analysis of the user response. First the general analysis and then part by part of the response.'
    )
    improved_response: str = Field(
        description='Create a improvement of the user response without changing the structure of the response, change only the minor errors to make it follow the criteria.'
    )
    response_score: int = Field(
        description='A score between 0 and 10 for the user response.'
    )

class TopicClassifierOutput(Replicator):
    # topic_choice: bool = Field(
    #     description='If the user response passed the score threshold.',
    #     alias='next_topic',
    # )
    # loop_back: bool = Field(
    #     description='If the user response not passed the score threshold.',
    #     alias='loop_back',
    # )
    topic: str = Field(
        description='Topic generated by the AI.'
    )
    user_input: str = Field(
        description='User input.'
    )


class TopicClassifierProcessor(Processor):
    def process(self, agent: Agent, messages: list[Message], llm: dict) -> dict | None:
        print(llm)
        # return {'topic_choice': True, 'loop_back': False}
        return {'topic': '...', 'user_input': '...'} 
        # if llm['response_score'] >= 8:
        #     return {'topic_choice': True, 'loop_back': False}
        # return {'topic_choice': False, 'loop_back': True}
        

def topic_classifier_fn(name: str):
    return Agent(
        name=name,
        role='user:linked',
        output_schema=TopicClassifierOutput,
        llm=LLM(
            model=LlmApi(model_name='gpt-4o-mini'),
            instructions=LlmInstructions(
                background="You are an English teacher AI. You will receive short informal responses from real-life speech-to-text conversations, and must evaluate only the linguistic quality of the English used, not the content or depth of the message.",
                tools=[],
                reasoning=False,
                steps=[
                    "Score only the linguistic quality: grammar, syntax, coherence, and clarity of English.",
                    "Do not penalize short, simple, or informal answers as long as they are correct and make sense.",
                    "Ignore minor errors clearly caused by speech-to-text (like missing punctuation or minor word confusions).",
                    "The only content-related check is whether the response shows basic understanding of the prompt.",
                    "Do not consider creativity, completeness, or depth in the score â€” only how well the English is written/spoken."
                ],
                output_schema=TopicClassifierLLMOutput
            ),
            debug=False
        ),
        processor=TopicClassifierProcessor(),
        num_workers=1,
    )   


async def send_inputs():
    #while True:
        # user_input = await asyncio.to_thread(input, "Input: ")
    topic_classifier.run(Messages(
        id='id_123',
        data=[
            Message(
                content={
                    'topic': 'Talk about why the LLMs struggles when they dont know the real answer',
                    'user_response': 'The LLMs are probabilistic predictors of the next words. They dont know what they know, they just calculate what is the next most likely word, so, if the the prompt is about a unkown topic by the LLM, it will get the list of probabilities of the words that most match the topic, and will create a coherent text with these words, even the information are completely wrong.' 
                }, 
                role='user'
            )
        ],
        source=None
    ))
    while True:
        await asyncio.sleep(5)

if __name__ == '__main__':
    os.system('cls')

    loop = asyncio.get_event_loop()
    loop.create_task(send_inputs())
    loop.run_forever()
